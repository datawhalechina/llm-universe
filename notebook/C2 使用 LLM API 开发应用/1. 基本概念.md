# 基本概念

[toc]

## 1. Prompt

Prompt 最初是 NLP（自然语言处理）研究者为下游任务设计出来的一种任务专属的输入模板，类似于一种任务（例如：分类，聚类等）会对应一种 Prompt。在 ChatGPT 推出并获得大量应用之后，Prompt 开始被推广为给大模型的所有输入。即，我们每一次访问大模型的输入为一个 Prompt，而大模型给我们的返回结果则被称为 Completion。

例如，在下面示例中，我们给 ChatGPT 的提问 “NLP 中的 Prompt 指什么”是我们的提问，其实也就是我们此次的 Prompt；而 ChatGPT 的返回结果就是此次的 Completion。也就是对于 ChatGPT 模型，该 Prompt 对应的 Completion 是下图的展示。

![ChatGPT Prompt Examples](../../figures/C2-1-prompt_example.png)

后续我们都将会使用 Prompt 替代给 LLM 的输入，使用 Completion 替代 LLM 的输出。同时，我们会结合具体案例，介绍如何设计 Prompt 能够充分发挥 LLM 的能力。

## 2. Temperature

LLM 生成是具有随机性的，在模型的顶层通过选取不同预测概率的预测结果来生成最后的结果。我们一般可以通过控制 temperature 参数来控制 LLM 生成结果的随机性与创造性。

Temperature 一般取值在 0~1 之间，当取值较低接近 0 时，预测的随机性会较低，产生更保守、可预测的文本，不太可能生成意想不到或不寻常的词。当取值较高接近 1 时，预测的随机性会较高，所有词被选择的可能性更大，会产生更有创意、多样化的文本，更有可能生成不寻常或意想不到的词。

例如，当我们使用 ChatGPT 要求其为我们想一个关于跨语言模型的硕士毕业论文选题，当我们将 temperature 设置为 0 时，模型回复为：

    题目：基于跨语言模型的机器翻译性能优化研究

    摘要：随着全球化的发展，跨语言交流的需求日益增长。机器翻译作为一种自动化翻译技术，为跨语言交流提供了便利。然而，由于语言之间的差异性，机器翻译系统在不同语言对之间的性能存在差异。本论文旨在通过研究跨语言模型，探索如何优化机器翻译的性能，提高翻译质量和准确性。

    关键词：跨语言模型，机器翻译，性能优化，翻译质量，准确性

    1. 引言
    1.1 研究背景和意义
    1.2 国内外研究现状
    1.3 研究目标和内容

    2. 跨语言模型的原理和方法
    2.1 传统机器翻译方法
    2.2 跨语言模型的基本原理
    2.3 跨语言模型的常用方法和技术

    3. 跨语言模型在机器翻译中的应用
    3.1 跨语言模型在机器翻译中的优势和挑战
    3.2 跨语言模型在不同语言对上的性能表现比较
    3.3 跨语言模型在特定领域机器翻译中的应用案例分析

    4. 跨语言模型的性能优化方法
    4.1 数据预处理和特征选择
    4.2 模型参数调优和训练策略
    4.3 跨语言模型与其他技术的结合应用

    5. 实验设计与结果分析
    5.1 实验设计和数据集介绍
    5.2 实验结果分析和对比
    5.3 实验结果的可行性和可靠性验证

    6. 结论与展望
    6.1 研究工作总结
    6.2 存在的问题和不足
    6.3 进一步研究方向和展望

    参考文献

    注：以上仅为一个选题示例，具体选题应根据个人兴趣和研究背景进行调整和修改。

当我们将 temperature 设置为 0.95 时，模型回复为：

    以下是关于跨语言模型的几个硕士毕业论文选题建议：

    1. 跨语言文本分类模型的比较和优化——通过比较不同跨语言模型的性能，分析其在不同语言之间的适应性和准确性，并尝试优化现有模型，提高跨语言文本分类的效果。

    2. 基于跨语言模型的机器翻译性能分析——通过比较不同跨语言模型在机器翻译任务中的表现，研究不同语言之间的短板和优势，并探讨如何针对性地改进跨语言机器翻译的性能。

    3. 跨语言情感分析模型的构建与应用——使用跨语言模型构建情感分析模型，通过比较模型在不同语言上的准确性和一致性，分析不同语言中情感表达的差异，并探索在多语言场景下的情感分析应用。

    4. 多任务学习下的跨语言模型训练——探索多任务学习下跨语言模型的训练方法和效果，通过同时训练多个任务来提高跨语言模型的泛化能力和性能，并验证多任务学习对跨语言模型的影响。

    5. 跨语言问答系统的构建与评估——构建跨语言问答系统，通过跨语言模型实现问题的自动解析和答案的生成，并评估系统在多语言环境下的效果和可用性。

    6. 基于预训练的跨语言模型的应用于语音识别——将预训练的跨语言模型应用于语音识别任务中，研究其对语音识别准确性和多语种适应性的影响，并比较不同模型对多语种语音数据的处理能力。

    选择适合自己兴趣和研究方向的选题，并与导师进行深入讨论和确认。

对于不同的问题与应用场景，我们可能需要设置不同的 temperature。例如，在本教程搭建的个人知识库助手项目中，我们一般将 temperature 设置为 0，从而保证助手对知识库内容的稳定使用，规避错误内容、模型幻觉；在产品智能客服、科研论文写作等场景中，我们同样更需要稳定性而不是创造性；但在个性化 AI、创意营销文案生成等场景中，我们就更需要创意性，从而更倾向于将 temperature 设置为较高的值。

## 3. System Prompt

System Prompt 是随着 ChatGPT API 开放并逐步得到大量使用的一个新兴概念，事实上，**它并不在大模型本身训练中得到体现，而是大模型服务方为提升用户体验所设置的一种策略**。

具体来说，在使用 ChatGPT API 时，你可以设置两种 Prompt：一种是 System Prompt，该种 Prompt 内容会在整个会话过程中持久地影响模型的回复，且相比于普通 Prompt 具有更高的重要性；另一种是 User Prompt，这更偏向于我们平时提到的 Prompt，即需要模型做出回复的输入。

我们一般设置 System Prompt 来对模型进行一些初始化设定，例如，我们可以在 System Prompt 中给模型设定我们希望它具备的人设如一个个人知识库助手等。System Prompt 一般在一个会话中仅有一个。在通过 System Prompt 设定好模型的人设或是初始设置后，我们可以通过 User Prompt 给出模型需要遵循的指令。例如，当我们需要一个幽默风趣的个人知识库助手，并向这个助手提问我今天有什么事时，可以构造如下的 Prompt：

```json
{
    "system prompt": "你是一个幽默风趣的个人知识库助手，可以根据给定的知识库内容回答用户的提问，注意，你的回答风格应是幽默风趣的",
    "user prompt": "我今天有什么事务？"
}
```

通过如上 Prompt 的构造，我们可以让模型以幽默风趣的风格回答用户提出的问题。