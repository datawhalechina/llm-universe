# ä¸‰ã€Fast api è¿›è¡Œå‰åç«¯åˆ†ç¦» ğŸ’¬

ç›®å‰æˆ‘ä»¬å·²ç»å®Œæˆäº†åŸºæœ¬çš„å¯è§†åŒ–é¡µé¢ï¼Œå¹¶ä¸”å¯ä»¥å®ç°å¯¹åº”çš„åŠŸèƒ½ã€‚

ä¸ºäº†æ–¹ä¾¿æ•´ä¸ªé¡¹ç›®çš„ç®¡ç†ï¼Œç°æœ‰çš„é¡¹ç›®é€šå¸¸é‡‡ç”¨å‰åç«¯åˆ†ç¦»çš„æ–¹å¼æ­å»ºï¼Œå‰åç«¯æ•°æ®é€šè¿‡ json çš„æ ¼å¼è¿›è¡Œä¼ è¾“ã€‚


FastAPI æ˜¯ä¸€ä¸ªç”¨äºæ„å»º API çš„ç°ä»£ã€å¿«é€Ÿï¼ˆé«˜æ€§èƒ½ï¼‰çš„ web æ¡†æ¶ï¼Œéå¸¸æ–¹ä¾¿ç”¨äºæ­å»ºæˆ‘ä»¬çš„å‰åç«¯åˆ†ç¦»çš„åº”ç”¨ã€‚

æˆ‘ä»¬é¦–å…ˆéœ€è¦å°†æˆ‘ä»¬ç”¨åˆ°çš„åç«¯å‡½æ•°è¿›è¡Œ FastAPI çš„å°è£…ã€‚å°è£… API ä¸å‰æ–‡ä¸­è®²è¿‡å°†å¤§æ¨¡å‹ API å°è£…æˆæœ¬åœ° API çš„æ–¹æ³•ç±»ä¼¼ï¼Œæˆ‘ä»¬é¦–å…ˆå¯¼å…¥ç¬¬ä¸‰æ–¹åº“å¹¶åˆ›å»ºä¸€ä¸ª API å¯¹è±¡ï¼š


```python
from fastapi import FastAPI
from pydantic import BaseModel
import os

app = FastAPI() # åˆ›å»º api å¯¹è±¡
```

æœ¬åœ° API ä¸€èˆ¬é€šè¿‡ POST æ–¹å¼è¿›è¡Œè®¿é—®ï¼Œå³å‚æ•°ä¼šé™„åŠ åœ¨ POST è¯·æ±‚ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å®šä¹‰ä¸€ä¸ªæ•°æ®æ¨¡å‹æ¥æ¥æ”¶ POST è¯·æ±‚ä¸­çš„æ•°æ®ï¼š


```python
# å®šä¹‰ä¸€ä¸ªæ•°æ®æ¨¡å‹ï¼Œç”¨äºæ¥æ”¶POSTè¯·æ±‚ä¸­çš„æ•°æ®
class Item(BaseModel):
    prompt : str # ç”¨æˆ· prompt
    model : str = "gpt-3.5-turbo"# ä½¿ç”¨çš„æ¨¡å‹
    temperature : float = 0.1# æ¸©åº¦ç³»æ•°
    if_history : bool = False # æ˜¯å¦ä½¿ç”¨å†å²å¯¹è¯åŠŸèƒ½
    # API_Key
    api_key: str = None
    # Secret_Key
    secret_key : str = None
    # access_token
    access_token: str = None
    # APPID
    appid : str = None
    # APISecret
    api_secret : str = None
    # æ•°æ®åº“è·¯å¾„
    db_path : str = "../../data_base/vector_db/chroma"
    # æºæ–‡ä»¶è·¯å¾„
    file_path : str = "../../data_base/knowledge_db"
    # prompt template
    prompt_template : str = template
    # Template å˜é‡
    input_variables : list = ["context","question"]
    # Embdding
    embedding : str = "openai"
    # Top K
    top_k : int = 5
    # embedding_key
    embedding_key : str = api_key
```

åœ¨ä¸Šé¢çš„ç±»ä¸­ï¼Œæˆ‘ä»¬å®šä¹‰äº†è¦è°ƒç”¨æˆ‘ä»¬å·²å°è£…çš„ QA_chain æ‰€éœ€è¦ä¼ å…¥çš„å‚æ•°ï¼Œå¯¹äºéå¿…é¡»å‚æ•°ï¼Œæˆ‘ä»¬éƒ½è®¾ç½®äº†é»˜è®¤å‚æ•°æ¥ä¿è¯è°ƒç”¨çš„ç®€æ´æ€§ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬å°±å¯ä»¥åˆ›å»ºä¸€ä¸ª POST è¯·æ±‚çš„ API ç«¯ç‚¹ï¼š


```python
@app.post("/answer/")
async def get_response(item: Item):

    # é¦–å…ˆç¡®å®šéœ€è¦è°ƒç”¨çš„é“¾
    if not item.if_history:
        # è°ƒç”¨ Chat é“¾
        chain = QA_chain_self(model=item.model, temperature=item.temperature, top_k=item.top_k, file_path=item.file_path, persist_path=item.db_path, 
                                appid=item.appid, api_key=item.api_key, embedding=item.embedding, template=template, api_secret=item.api_secret, embedding_key=item.embedding_key)

        response = chain.answer(question = item.prompt)
    
        return response
    
    # ç”±äº API å­˜åœ¨å³æ—¶æ€§é—®é¢˜ï¼Œä¸èƒ½æ”¯æŒå†å²é“¾
    else:
        return "API ä¸æ”¯æŒå†å²é“¾"
```

ä¸Šè¿°ç«¯ç‚¹çš„ä¸šåŠ¡é€»è¾‘å¾ˆç®€å•ï¼Œå³è°ƒç”¨æˆ‘ä»¬å·²å°è£…çš„ QA_chain_self å¯¹è±¡è¿›è¡Œå®ä¾‹åŒ–ä¸å›ç­”å³å¯ã€‚é€šè¿‡è¿™ä¸€ä¸ªç«¯ç‚¹å¯åŠ¨ï¼Œæˆ‘ä»¬ä¾¿å¯é€šè¿‡è®¿é—®æœ¬åœ° 8000 ç«¯å£æ¥è°ƒç”¨ä¸ªäººçŸ¥è¯†åº“åŠ©æ‰‹çš„æœåŠ¡å•¦ï¼Œæˆ‘ä»¬åªéœ€è¦é€šè¿‡ä¸‹åˆ—å‘½ä»¤å¯åŠ¨ï¼š 


```python
uvicorn app:app 
```

å®Œæ•´é¡¹ç›®ä»£ç è¯·æŸ¥é˜… [project/serve](/project/serve/) ç›®å½•~